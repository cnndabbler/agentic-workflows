{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnndabbler/agentic-workflows/blob/main/run_pydantic_ai_with_Ollama_and_DeepSeek_R1_Step_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MJe6AusVtI"
      },
      "source": [
        "## Pydantic Agents running DeepSeek-R1 using Ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic_ai\n",
        "!pip install -q pydantic\n",
        "!pip install -q rich"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oodiS71x0Jy",
        "outputId": "0be8b98e-e2c1-4d5d-c4e9-118b7a580cb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/223.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.2/223.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiate Ollama and load the models in the GPU"
      ],
      "metadata": {
        "id": "bCpdkKPzc4X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Run the Ollama installation script\n",
        "subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True, check=True)\n",
        "\n",
        "# Start the Ollama server in the background\n",
        "ollama_process = subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "# Allow some time for the server to initialize\n",
        "time.sleep(5)\n",
        "\n",
        "# Reasoner model on L4 GPU\n",
        "# !ollama pull deepseek-r1:14b > /dev/null 2>&1\n",
        "# !ollama pull deepseek-r1:14b\n",
        "\n",
        "# Reasoner model on A100 GPU\n",
        "!ollama pull deepseek-r1:32b > /dev/null 2>&1\n",
        "# !ollama pull deepseek-r1:32b\n",
        "\n",
        "# Parser model\n",
        "!ollama pull qwen2.5 > /dev/null 2>&1\n",
        "# !ollama pull qwen2.5\n",
        "\n",
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUhagysPHI1h",
        "outputId": "4223a6ce-1d6d-480c-81ab-ed4437c2553d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME               ID              SIZE      MODIFIED               \n",
            "qwen2.5:latest     845dbda0ea48    4.7 GB    Less than a second ago    \n",
            "deepseek-r1:32b    38056bbcbb2d    19 GB     38 seconds ago            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the two models have been loaded in the GPU"
      ],
      "metadata": {
        "id": "U6C4WDki4NsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2w_AkPBrQV2",
        "outputId": "111100b1-9165-4398-a3f5-eb6804c1fc4c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME               ID              SIZE      MODIFIED       \n",
            "qwen2.5:latest     845dbda0ea48    4.7 GB    30 minutes ago    \n",
            "deepseek-r1:32b    38056bbcbb2d    19 GB     31 minutes ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Ollama Models for Agentic AI"
      ],
      "metadata": {
        "id": "vZ_fW4y-S4oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field, confloat\n",
        "import asyncio\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich import box"
      ],
      "metadata": {
        "id": "4g5kdVtvxUau"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "\n",
        "# DeepSeekR1\n",
        "deepseek_reasoner_model = OpenAIModel(\n",
        "    'deepseek-r1:32b',\n",
        "    # 'deepseek-r1:14b',\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"whatever\",\n",
        ")\n",
        "\n",
        "deepseek_parser_model = OpenAIModel(\n",
        "    'qwen2.5',\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"whatever\",\n",
        ")"
      ],
      "metadata": {
        "id": "jFGiFqK2fkSJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRBMh9nS_X9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pydantic Classes"
      ],
      "metadata": {
        "id": "SqU7mlU5iAW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field, confloat\n",
        "import asyncio\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich import box\n",
        "\n",
        "# Define the Joke model\n",
        "class Joke(BaseModel):\n",
        "    setup: str = Field(..., description=\"The setup part of the joke\")\n",
        "    punchline: str = Field(..., description=\"The punchline of the joke\")\n",
        "    category: str = Field(..., description=\"Category of the joke (e.g., 'pun', 'wordplay', 'dad joke')\")\n",
        "    thinking: str = Field(..., description=\"the thought process and planning without change\")\n"
      ],
      "metadata": {
        "id": "IEridau5f_ja"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Joke Creator Agent\n",
        "joke_creator = Agent(\n",
        "    model=deepseek_reasoner_model,\n",
        "    result_type=str,\n",
        "    deps_type=str,  # Takes a string prompt as input\n",
        "    system_prompt=(\n",
        "        \"You are a joke creator that specializes in creating funny, family-friendly dad jokes. \"\n",
        "        \"Your output MUST follow this EXACT format with EXACT field names:\\n\\n\"\n",
        "        \"Thinking: \\n<think>\\n[your entire thought process without changes]\\n</think>\\n\\n\"\n",
        "        \"Setup: [setup text]\\n\"\n",
        "        \"Punchline: [punchline text]\\n\"\n",
        "        \"Category: [category]\\n\"\n",
        "        # \"Thinking: [brief explanation]\\n\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "48zghcKygXJR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8TCaMwO-yFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binding to Pydantic Joke class: Failure\n",
        "\n",
        "- You will see the following error:\n",
        "- BadRequestError: Error code: 400 - {'error': {'message': 'registry.ollama.ai/library/deepseek-r1:32b does not support tools', 'type': 'api_error', 'param': None, 'code': None}}"
      ],
      "metadata": {
        "id": "a7zl3dzxg8Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Joke Creator Agent binding result_type to Joke class\n",
        "joke_creator_with_pydantic_class = Agent(\n",
        "    model=deepseek_reasoner_model,\n",
        "    result_type=Joke,\n",
        "    deps_type=str,  # Takes a string prompt as input\n",
        "    system_prompt=(\n",
        "        \"You are a joke creator that specializes in creating funny, family-friendly dad jokes. \"\n",
        "        \"Your output MUST follow this EXACT format with EXACT field names:\\n\\n\"\n",
        "        \"Thinking: \\n<think>\\n[your detailed thought process between the tags without any changes]\\n</think>\\n\\n\"\n",
        "        \"Setup: [setup text]\\n\"\n",
        "        \"Punchline: [punchline text]\\n\"\n",
        "        \"Category: [category]\\n\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "Akl5LYdEfsD4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Only run the cell below to verify that Pydantic Agent does not support DeepSeek-R1"
      ],
      "metadata": {
        "id": "Ww2tiWVJb5dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# joke_text = await joke_creator_with_pydantic_class.run(\"Create a dad joke\")\n",
        "# print(\"\\nRaw joke text:\")\n",
        "# print(\"-\" * 50)\n",
        "# print(joke_text.data)\n",
        "# print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "CSWsVKwuhLsB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Parser Agent to successfully bind to Pydantic Class"
      ],
      "metadata": {
        "id": "eAHiaJTXgE8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Parser Agent with 3 retries max\n",
        "joke_parser = Agent(\n",
        "    model=deepseek_parser_model,\n",
        "    result_type=Joke,\n",
        "    deps_type=str,  # Takes raw text as input\n",
        "    retries=5,\n",
        "    system_prompt=(\n",
        "        \"You are a joke parser that extracts components from the input text to create a Joke object. \"\n",
        "        \"Your ONLY task is to find and extract these components from the input text without making any changes:\\n\"\n",
        "        \"1. The setup (after 'Setup:')\\n\"\n",
        "        \"2. The punchline (after 'Punchline:')\\n\"\n",
        "        \"3. The category (after 'Category:')\\n\"\n",
        "        \"4. The thinking (exact text tags without changes between <think> tags)\\n\\n\"\n",
        "        \"Return the components in this format:\\n\"\n",
        "        \"setup=[text after Setup:]\\n\"\n",
        "        \"punchline=[text after Punchline:]\\n\"\n",
        "        \"category=[text after Category:]\\n\"\n",
        "        \"thinking: \\n<think>\\n[your detailed thought process between the tags without any changes]\\n</think>\\n\\n\"\n",
        "        \"DO NOT generate new content or modify the text in any way.\\n\"\n",
        "        \"DO NOT include any other text in your response.\"\n",
        "    ),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DMc379Ea9fS2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create raw joke text using DeepSeek-R1\n",
        "print(\"Creating joke...\")\n",
        "joke_text = await joke_creator.run(\n",
        "    \"Create a dad joke\",\n",
        "    model_settings={\"max_tokens\": 1000}\n",
        "    )\n",
        "if not joke_text:\n",
        "    raise ValueError(\"Failed to create joke\")\n",
        "print(\"\\nRaw joke text:\")\n",
        "print(\"-\" * 50)\n",
        "print(joke_text.data)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-X-9mBB1XJu",
        "outputId": "94b24e2e-5fb2-4a6a-ca99-7cf4f7da62f9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating joke...\n",
            "\n",
            "Raw joke text:\n",
            "--------------------------------------------------\n",
            "<think>\n",
            "Okay, so I need to create a dad joke using that specific format. The user provided an example where they used \"octopus\" and \"tentacles\" as wordplay, categorized it under marine life.\n",
            "\n",
            "Hmm, I should think of another type that's family-friendly and has a pun or play on words. Maybe something involving animals since that's always fun. Let me brainstorm...\n",
            "\n",
            "What about something with horses? I remember there are jokes like why did the horse jump in the bathtub? Because it heard it rained on plains. Wait, that might be more of a kid joke. Or maybe using \"neighth\" as a play on \"night.\" But how can I make that into a dad joke?\n",
            "\n",
            "Alternatively, what about cows? Cows moos and maybe something related to milk. Like why did the cow cross the road? To get to the udder side! Oh, that's a classic one.\n",
            "\n",
            "Wait, let me see... Maybe something with elephants, like their trunks or how they use them. Or perhaps birds and nests. Let me think of wordplay for nest. Maybe \"nest\" as in \"best,\" but that might not be funny enough. \n",
            "\n",
            "Wait, another idea: why did the turkey cross the road? Because it had a drum stick! But is that a dad joke? It's more of a traditional punny joke.\n",
            "\n",
            "Oh, here's an idea with chickens or eggs. Maybe why did the chicken go to school... To get egg-sellent grades! That's a play on \"excellent\" and \"egg.\" Yeah, that works. Let me structure it in the given format. So setup is asking why did the chicken..., punchline about egg-sellent grades. Category would be farm animals or birds.\n",
            "\n",
            "I think that fits well. Make sure it's clean and family-friendly, no adult humor here.\n",
            "</think>\n",
            "\n",
            "Setup: Why did the chicken go to school?\n",
            "\n",
            "Punchline: To get egg-sellent grades!\n",
            "\n",
            "Category: Farm Animals/Birds\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Parse the text into a Pydantic model using Qwen2.5\n",
        "print(\"\\nParsing joke...\")\n",
        "parsed_joke = await joke_parser.run(\n",
        "    joke_text.data)\n",
        "if not parsed_joke:\n",
        "    raise ValueError(\"Failed to parse joke\")\n",
        "print(\"\\nParsed joke text:\")\n",
        "print(\"-\" * 50)\n",
        "print(parsed_joke.data)\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HxYYd3nnou5",
        "outputId": "abb012d2-6e89-43fe-a604-c10264b122e3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parsing joke...\n",
            "\n",
            "Parsed joke text:\n",
            "--------------------------------------------------\n",
            "setup='Why did the chicken go to school?' punchline='To get egg-sellent grades!' category='Farm Animals/Birds' thinking=\"<think>I started with a classic setup of why did the chicken go to school since it's familiar and can resonate well. The punchline 'To get egg-sellent grades!' uses wordplay on 'excellent' with 'egg' which keeps it clean and family-friendly, fitting the dad joke category well.</think>\"\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Display results\n",
        "console = Console()\n",
        "\n",
        "# Create assessment table\n",
        "table = Table(title=\"Joke Parsed\", box=box.ROUNDED)\n",
        "table.add_column(\"Property\", style=\"cyan\", width=20)\n",
        "table.add_column(\"Value\", style=\"yellow\")\n",
        "\n",
        "# Add joke content\n",
        "table.add_row(\"Setup\", parsed_joke.data.setup)\n",
        "table.add_row(\"Punchline\", parsed_joke.data.punchline)\n",
        "table.add_row(\"Category\", parsed_joke.data.category)\n",
        "table.add_row(\"\",\"\")\n",
        "\n",
        "\n",
        "# Add thinking process\n",
        "table.add_row(\"\", \"\")\n",
        "table.add_row(\"[bold]Thinking Process\", \"\")\n",
        "thinking_lines = parsed_joke.data.thinking.split('\\n')\n",
        "for line in thinking_lines:\n",
        "    if line.strip():\n",
        "        table.add_row(\"\", line)\n",
        "\n",
        "# Print the table\n",
        "console.print(\"\\n\")\n",
        "console.print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "HFBWDE1AnhbY",
        "outputId": "a812f1c3-2591-45dd-f509-f97d82a604a4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                    Joke Parsed                                                    \u001b[0m\n",
              "╭──────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│\u001b[1m \u001b[0m\u001b[1mProperty            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue                                                                                   \u001b[0m\u001b[1m \u001b[0m│\n",
              "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│\u001b[36m \u001b[0m\u001b[36mSetup               \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mWhy did the chicken go to school?                                                       \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mPunchline           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTo get egg-sellent grades!                                                              \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCategory            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mFarm Animals/Birds                                                                      \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[1;36mThinking Process\u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m<think>I started with a classic setup of why did the chicken go to school since it's    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mfamiliar and can resonate well. The punchline 'To get egg-sellent grades!' uses wordplay\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mon 'excellent' with 'egg' which keeps it clean and family-friendly, fitting the dad joke\u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mcategory well.</think>                                                                  \u001b[0m\u001b[33m \u001b[0m│\n",
              "╰──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Joke Parsed                                                    </span>\n",
              "╭──────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│<span style=\"font-weight: bold\"> Property             </span>│<span style=\"font-weight: bold\"> Value                                                                                    </span>│\n",
              "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Setup                </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Why did the chicken go to school?                                                        </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Punchline            </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> To get egg-sellent grades!                                                               </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Category             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Farm Animals/Birds                                                                       </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Thinking Process</span><span style=\"color: #008080; text-decoration-color: #008080\">     </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> &lt;think&gt;I started with a classic setup of why did the chicken go to school since it's     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> familiar and can resonate well. The punchline 'To get egg-sellent grades!' uses wordplay </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> on 'excellent' with 'egg' which keeps it clean and family-friendly, fitting the dad joke </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> category well.&lt;/think&gt;                                                                   </span>│\n",
              "╰──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "name": "run-pydantic-ai-with-Ollama-and-DeepSeek-R1.ipynb",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}