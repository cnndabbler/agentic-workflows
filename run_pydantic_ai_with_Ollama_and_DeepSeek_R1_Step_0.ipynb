{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cnndabbler/agentic-workflows/blob/main/run_pydantic_ai_with_Ollama_and_DeepSeek_R1_Step_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MJe6AusVtI"
      },
      "source": [
        "## Pydantic Agents running DeepSeek-R1 using Ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydantic_ai\n",
        "!pip install -q pydantic\n",
        "!pip install -q rich"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oodiS71x0Jy",
        "outputId": "f0b11d5e-78db-4bd7-af20-7268c13386f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/223.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.2/223.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/210.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiate Ollama and load the models in the GPU"
      ],
      "metadata": {
        "id": "bCpdkKPzc4X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Run the Ollama installation script\n",
        "subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True, check=True)\n",
        "\n",
        "# Start the Ollama server in the background\n",
        "ollama_process = subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "# Allow some time for the server to initialize\n",
        "time.sleep(5)\n",
        "\n",
        "# Reasoner model on L4 GPU\n",
        "# !ollama pull deepseek-r1:14b > /dev/null 2>&1\n",
        "# !ollama pull deepseek-r1:14b\n",
        "\n",
        "# Reasoner model on A100 GPU\n",
        "!ollama pull deepseek-r1:32b > /dev/null 2>&1\n",
        "# !ollama pull deepseek-r1:32b\n",
        "\n",
        "# Parser model\n",
        "!ollama pull qwen2.5 > /dev/null 2>&1\n",
        "# !ollama pull qwen2.5\n",
        "\n",
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUhagysPHI1h",
        "outputId": "66a8b518-6606-494b-d5fe-d19f47c456f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME               ID              SIZE      MODIFIED               \n",
            "qwen2.5:latest     845dbda0ea48    4.7 GB    Less than a second ago    \n",
            "deepseek-r1:32b    38056bbcbb2d    19 GB     37 seconds ago            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2w_AkPBrQV2",
        "outputId": "e57787d1-4e55-4011-8aec-c3afec5bf070"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME               ID              SIZE      MODIFIED               \n",
            "qwen2.5:latest     845dbda0ea48    4.7 GB    Less than a second ago    \n",
            "deepseek-r1:32b    38056bbcbb2d    19 GB     37 seconds ago            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ollama Models"
      ],
      "metadata": {
        "id": "vZ_fW4y-S4oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field, confloat\n",
        "import asyncio\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich import box"
      ],
      "metadata": {
        "id": "4g5kdVtvxUau"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "\n",
        "# DeepSeekR1\n",
        "deepseek_reasoner_model = OpenAIModel(\n",
        "    'deepseek-r1:32b',\n",
        "    # 'deepseek-r1:14b',\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"whatever\",\n",
        ")\n",
        "\n",
        "deepseek_parser_model = OpenAIModel(\n",
        "    'qwen2.5',\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"whatever\",\n",
        ")"
      ],
      "metadata": {
        "id": "jFGiFqK2fkSJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pydantic Classes"
      ],
      "metadata": {
        "id": "SqU7mlU5iAW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field, confloat\n",
        "import asyncio\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich import box\n",
        "\n",
        "# Define the Joke model\n",
        "class Joke(BaseModel):\n",
        "    setup: str = Field(..., description=\"The setup part of the joke\")\n",
        "    punchline: str = Field(..., description=\"The punchline of the joke\")\n",
        "    category: str = Field(..., description=\"Category of the joke (e.g., 'pun', 'wordplay', 'dad joke')\")\n",
        "    thinking: str = Field(..., description=\"the thought process and planning\")\n"
      ],
      "metadata": {
        "id": "IEridau5f_ja"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Joke Creator Agent\n",
        "joke_creator = Agent(\n",
        "    model=deepseek_reasoner_model,\n",
        "    result_type=str,\n",
        "    deps_type=str,  # Takes a string prompt as input\n",
        "    system_prompt=(\n",
        "        \"You are a joke creator that specializes in creating funny, family-friendly dad jokes. \"\n",
        "        \"Your output MUST follow this EXACT format with EXACT field names:\\n\\n\"\n",
        "        \"Thinking: \\n<think>\\n[your detailed thought process without changes]\\n</think>\\n\\n\"\n",
        "        \"Setup: [setup text]\\n\"\n",
        "        \"Punchline: [punchline text]\\n\"\n",
        "        \"Category: [category]\\n\"\n",
        "        # \"Thinking: [brief explanation]\\n\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "48zghcKygXJR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binding to Pydantic Joke class: Failure\n",
        "\n",
        "- You will see the following error:\n",
        "- BadRequestError: Error code: 400 - {'error': {'message': 'registry.ollama.ai/library/deepseek-r1:32b does not support tools', 'type': 'api_error', 'param': None, 'code': None}}"
      ],
      "metadata": {
        "id": "a7zl3dzxg8Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Joke Creator Agent binding result_type to Joke class\n",
        "joke_creator_with_pydantic_class = Agent(\n",
        "    model=deepseek_reasoner_model,\n",
        "    result_type=Joke,\n",
        "    deps_type=str,  # Takes a string prompt as input\n",
        "    system_prompt=(\n",
        "        \"You are a joke creator that specializes in creating funny, family-friendly dad jokes. \"\n",
        "        \"Your output MUST follow this EXACT format with EXACT field names:\\n\\n\"\n",
        "        \"Thinking: \\n<think>\\n[your detailed thought process without changes]\\n</think>\\n\\n\"\n",
        "        \"Setup: [setup text]\\n\"\n",
        "        \"Punchline: [punchline text]\\n\"\n",
        "        \"Category: [category]\\n\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "Akl5LYdEfsD4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: Only run the cell below to verify that Pydantic Agent does not support DeepSeek-R1"
      ],
      "metadata": {
        "id": "Ww2tiWVJb5dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# joke_text = await joke_creator_with_pydantic_class.run(\"Create a dad joke\")\n",
        "# print(\"\\nRaw joke text:\")\n",
        "# print(\"-\" * 50)\n",
        "# print(joke_text.data)\n",
        "# print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "CSWsVKwuhLsB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a Parser Agent to successfully bind to Pydantic Class"
      ],
      "metadata": {
        "id": "eAHiaJTXgE8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Parser Agent with 3 retries max\n",
        "joke_parser = Agent(\n",
        "    model=deepseek_parser_model,\n",
        "    result_type=Joke,\n",
        "    deps_type=str,  # Takes raw text as input\n",
        "    retries=3,\n",
        "    system_prompt=(\n",
        "        \"You are a joke parser that extracts components from the input text to create a Joke object. \"\n",
        "        \"Your ONLY task is to find and extract these components from the input text:\\n\"\n",
        "        \"1. The setup (after 'Setup:')\\n\"\n",
        "        \"2. The punchline (after 'Punchline:')\\n\"\n",
        "        \"3. The category (after 'Category:')\\n\"\n",
        "        \"4. The thinking (between <think> tags)\\n\\n\"\n",
        "        \"Return the components in this format:\\n\"\n",
        "        \"setup=[text after Setup:]\\n\"\n",
        "        \"punchline=[text after Punchline:]\\n\"\n",
        "        \"category=[text after Category:]\\n\"\n",
        "        \"thinking=[text between <think> tags]\\n\\n\"\n",
        "        \"DO NOT generate new content or modify the text in any way.\\n\"\n",
        "        \"DO NOT include any other text in your response.\"\n",
        "    ),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DMc379Ea9fS2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create raw joke text using DeepSeek-R1\n",
        "print(\"Creating joke...\")\n",
        "joke_text = await joke_creator.run(\"Create a dad joke\")\n",
        "if not joke_text:\n",
        "    raise ValueError(\"Failed to create joke\")\n",
        "print(\"\\nRaw joke text:\")\n",
        "print(\"-\" * 50)\n",
        "print(joke_text.data)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-X-9mBB1XJu",
        "outputId": "3f080fba-939d-4ad4-f31b-cb681fa99bd4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating joke...\n",
            "\n",
            "Raw joke text:\n",
            "--------------------------------------------------\n",
            "<think>\n",
            "Okay, so I need to create a dad joke following the given format. Let me think about how to approach this.\n",
            "\n",
            "First, I should understand what a dad joke typically is. They're usually simple, pun-based jokes that often involve wordplay or a twist at the end. They’re meant to be humorous and family-friendly, so nothing too complex or risqué.\n",
            "\n",
            "Looking back at the example provided earlier: the setup was about painting a house, and the punchline involved the painter having \"good walls.\" That's a classic dad joke structure—using a play on words with a common phrase related to the subject. In this case, \"walls\" is both literal (in the context of painting) and part of a pun (\"w-alls\").\n",
            "\n",
            "Another example was: \"Why don’t skeletons fight each other? They don't have the guts.\" Again, it's taking a simple scenario, adding a fun twist with wordplay on \"guts,\" which can mean both courage and internal organs.\n",
            "\n",
            "So, I need to come up with something similar. Maybe think of an activity or situation that people are familiar with, and then find a pun or wordplay related to that.\n",
            "\n",
            "Let me brainstorm some ideas:\n",
            "\n",
            "1. Gardening: Maybe something about watering plants.\n",
            "2. Cooking: Perhaps something with ingredients.\n",
            "3. Animals: Like cats or dogs doing something funny.\n",
            "4. Technology: Maybe something related to computers or phones.\n",
            "\n",
            "Wait, the user's previous response included a joke about painters and good walls. I should avoid repeating that exact setup but can consider similar themes.\n",
            "\n",
            "Let me try gardening because it’s relatable, and there are lots of puns possible with plants, watering, etc.\n",
            "\n",
            "Setup idea: Why did the gardener plant his favorite book?\n",
            "\n",
            "Punchline twist: Because he wanted to grow a \"good read.\"\n",
            "\n",
            "That plays on \"good read\" which is both about books and could involve growing something in a garden. It fits well as a dad joke because it's simple, uses wordplay, and is family-friendly.\n",
            "\n",
            "So putting it together:\n",
            "\n",
            "Setup: Why did the gardener plant his favorite book?\n",
            "\n",
            "Punchline: Because he wanted to grow a \"good read.\"\n",
            "\n",
            "Category: Gardening\n",
            "\n",
            "I think that works. The pun is clear, and it relates to a common activity (gardening) with an unexpected twist involving books. It should be easy for people to get the joke without any complicated language or concepts.\n",
            "</think>\n",
            "\n",
            "Setup: Why did the gardener plant his favorite book?\n",
            "\n",
            "Punchline: Because he wanted to grow a \"good read.\"\n",
            "\n",
            "Category: Gardening\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Parse the text into a Pydantic model using Qwen2.5\n",
        "print(\"\\nParsing joke...\")\n",
        "parsed_joke = await joke_parser.run(\n",
        "    joke_text.data)\n",
        "if not parsed_joke:\n",
        "    raise ValueError(\"Failed to parse joke\")\n",
        "print(\"\\nParsed joke text:\")\n",
        "print(\"-\" * 50)\n",
        "print(parsed_joke.data)\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HxYYd3nnou5",
        "outputId": "4ac68059-d032-4655-c7a2-42b17a774f8d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parsing joke...\n",
            "\n",
            "Parsed joke text:\n",
            "--------------------------------------------------\n",
            "setup='Why did the gardener plant his favorite book?' punchline='Because he wanted to grow a \"good read.\",' category='Gardening' thinking='I came up with a gardening-themed setup involving planting a book, and used wordplay on \"good read\" which puns both about books and growing something in a garden. This fits well as a dad joke because it\\'s simple, uses wordplay, and is family-friendly.'\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Display results\n",
        "console = Console()\n",
        "\n",
        "# Create assessment table\n",
        "table = Table(title=\"Joke Parsed\", box=box.ROUNDED)\n",
        "table.add_column(\"Property\", style=\"cyan\", width=20)\n",
        "table.add_column(\"Value\", style=\"yellow\")\n",
        "\n",
        "# Add joke content\n",
        "table.add_row(\"Setup\", parsed_joke.data.setup)\n",
        "table.add_row(\"Punchline\", parsed_joke.data.punchline)\n",
        "table.add_row(\"Category\", parsed_joke.data.category)\n",
        "table.add_row(\"\",\"\")\n",
        "\n",
        "\n",
        "# Add thinking process\n",
        "table.add_row(\"\", \"\")\n",
        "table.add_row(\"[bold]Thinking Process\", \"\")\n",
        "thinking_lines = parsed_joke.data.thinking.split('\\n')\n",
        "for line in thinking_lines:\n",
        "    if line.strip():\n",
        "        table.add_row(\"\", line)\n",
        "\n",
        "# Print the table\n",
        "console.print(\"\\n\")\n",
        "console.print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "HFBWDE1AnhbY",
        "outputId": "16750b99-900c-4803-f48c-c7b07425acf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                                    Joke Parsed                                                    \u001b[0m\n",
              "╭──────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│\u001b[1m \u001b[0m\u001b[1mProperty            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mValue                                                                                   \u001b[0m\u001b[1m \u001b[0m│\n",
              "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│\u001b[36m \u001b[0m\u001b[36mSetup               \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mWhy did the gardener plant his favorite book?                                           \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mPunchline           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mBecause he wanted to grow a \"good read.\",                                               \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCategory            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mGardening                                                                               \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[1;36mThinking Process\u001b[0m\u001b[36m    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m                                                                                        \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mI came up with a gardening-themed setup involving planting a book, and used wordplay on \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33m\"good read\" which puns both about books and growing something in a garden. This fits    \u001b[0m\u001b[33m \u001b[0m│\n",
              "│\u001b[36m                      \u001b[0m│\u001b[33m \u001b[0m\u001b[33mwell as a dad joke because it's simple, uses wordplay, and is family-friendly.          \u001b[0m\u001b[33m \u001b[0m│\n",
              "╰──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Joke Parsed                                                    </span>\n",
              "╭──────────────────────┬──────────────────────────────────────────────────────────────────────────────────────────╮\n",
              "│<span style=\"font-weight: bold\"> Property             </span>│<span style=\"font-weight: bold\"> Value                                                                                    </span>│\n",
              "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────────────┤\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Setup                </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Why did the gardener plant his favorite book?                                            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Punchline            </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Because he wanted to grow a \"good read.\",                                                </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Category             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> Gardening                                                                                </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Thinking Process</span><span style=\"color: #008080; text-decoration-color: #008080\">     </span>│<span style=\"color: #808000; text-decoration-color: #808000\">                                                                                          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> I came up with a gardening-themed setup involving planting a book, and used wordplay on  </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> \"good read\" which puns both about books and growing something in a garden. This fits     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> well as a dad joke because it's simple, uses wordplay, and is family-friendly.           </span>│\n",
              "╰──────────────────────┴──────────────────────────────────────────────────────────────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "name": "run-pydantic-ai-with-Ollama-and-DeepSeek-R1.ipynb",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}